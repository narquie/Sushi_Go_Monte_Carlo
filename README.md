# Sushi_Go_Monte_Carlo
Monte Carlo for Sushi Go (to be used with reinforcement learning)

After you clone the repository, go ahead and run Sushi_Go_Player_2.py

If you want a harder challenge, run Sushi_Go_Player_3.py

The .pkl file will give the bots their directions for how to play.

UI isn't great, but tells you all available actions "Categorized As:" and the board state (with indications for which cards are which).

Have fun!
